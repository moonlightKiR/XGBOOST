# -*- coding: utf-8 -*-
import os
import math
import warnings
import pandas as pd
import numpy as np
import scipy.stats as stats

import matplotlib.pyplot as plt

import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_classif
from sklearn.decomposition import PCA
from imblearn.over_sampling import SMOTE

warnings.filterwarnings('ignore')
"""Funciones de EDA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AMMgRD2LokngHhwgaeSibBbYBfD8xmGl
"""

def transform_dataframe(df):
    #Dividimos la variable data en 784 columnas referentes a cada pixel
    df.drop('data', inplace= True)
    return df 

def data_resume_info(df):
    print("--- Informacion General ---")
    df.info()

    print("\n--- Valores Nulos ---")
    print(df.isnull().sum())

    print("\n--- Filas Duplicadas ---")
    print(f"Total: {df.duplicated().sum()}")

    print("\n--- Estadisticas Descriptivas ---")
    return df.describe(include='all')

def outlier_impact_test(df):
    resultados = []
    cols_numericas = df.select_dtypes(include='number').columns

    for col in cols_numericas:
        datos = df[col].dropna()
        media_orig = datos.mean()
        std_orig = datos.std()
        #Esta es la formula del boxplot aplicada de manera manual con los cuartiles
        Q1 = datos.quantile(0.25)
        Q3 = datos.quantile(0.75)
        IQR = Q3 - Q1
        limite_inf = Q1 - 1.5 * IQR
        limite_sup = Q3 + 1.5 * IQR

        datos_sin_outliers = datos[(datos >= limite_inf) & (datos <= limite_sup)]
        if len(datos) == len(datos_sin_outliers):
            continue

        # 4.Duplicado de la base sin los outliers
        media_new = datos_sin_outliers.mean()
        std_new = datos_sin_outliers.std()

        #Cambio porcentual de nuestras variables al quitar los outliers
        cambio_media = ((media_new - media_orig) / media_orig) * 100
        reduccion_varianza = ((std_new - std_orig) / std_orig) * 100
        resultados.append({
            'Variable': col,
            'Num_Outliers_Eliminados': len(datos) - len(datos_sin_outliers),
            '%_Datos_Perdidos': round((1 - len(datos_sin_outliers)/len(datos))*100, 2),
            'Delta_MEdia_(%)': round(cambio_media, 2),
            'Delta_STD_(%)': round(reduccion_varianza, 2)
        })
    # Devolvemos tabla
    return pd.DataFrame(resultados).sort_values(by='Delta_STD_(%)', ascending=True)

def graf_box_hist(df):
    df_vis = df.select_dtypes(include='number')
    cols = df_vis.columns
    total_vars = len(cols)
    if total_vars == 0:
        print("No hay columnas numéricas para graficar.")
        return

    # --- 1. Histogramas ---
    axes_hist = df_vis.hist(bins=20, figsize=(15, 10), edgecolor='black', grid=False)
    axes_hist_flat = axes_hist.flatten()
    for ax in axes_hist_flat:
        col_name = ax.get_title()
        if col_name in cols:
            mean_val = df_vis[col_name].mean()
            ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Media: {mean_val:.2f}')
            ax.legend(fontsize='small')
    plt.tight_layout()
    plt.show()

    # --- 2. Boxplots ---
    cols_grid = 3
    rows_needed = math.ceil(total_vars / cols_grid)
    fig, axes_box = plt.subplots(nrows=rows_needed, ncols=cols_grid,
                                 figsize=(15, 4 * rows_needed))
    axes_box_flat = axes_box.flatten() if total_vars > 1 else [axes_box]
    for i, col_name in enumerate(cols):
        ax = axes_box_flat[i]
        sns.boxplot(x=df_vis[col_name], ax=ax, color='skyblue')
        ax.set_title(col_name, fontsize=10, fontweight='bold')
        ax.set_xlabel('')
    for j in range(i + 1, len(axes_box_flat)):
        fig.delaxes(axes_box_flat[j])

    plt.tight_layout()
    plt.show()

def plot_binary_bars(df, grid_cols=3, figsize_width=15):
    binary_cols = [col for col in df.columns if df[col].nunique() == 2]
    total_vars = len(binary_cols)

    if total_vars == 0:
        print("No se encontraron variables binarias.")
        return

    resumen_list = []
    for col in binary_cols:
        conteo = df[col].value_counts(normalize=True) * 100
        fila = {'Variable': col}
        for valor, porcentaje in conteo.items():
            fila[f'Valor_{valor} (%)'] = round(porcentaje, 2)
        resumen_list.append(fila)

    df_resumen = pd.DataFrame(resumen_list).fillna(0)

    cols_ordenadas = ['Variable'] + sorted([c for c in df_resumen.columns if c != 'Variable'])
    df_resumen = df_resumen[cols_ordenadas]

    print("--- Distribución Porcentual ---")
    print(df_resumen.to_string(index=False))
    print("-" * 30)

    # --- 2. Generación de Gráficos ---
    rows_needed = math.ceil(total_vars / grid_cols)
    fig, axes = plt.subplots(nrows=rows_needed, ncols=grid_cols,
                             figsize=(figsize_width, 4 * rows_needed))
    axes_flat = axes.flatten() if total_vars > 1 else [axes]
    for i, col in enumerate(binary_cols):
        ax = axes_flat[i]
        sns.countplot(x=df[col], ax=ax, palette='viridis', edgecolor='black')
        ax.set_title(col, fontsize=10, fontweight='bold')
        ax.set_xlabel('')
        ax.set_ylabel('Frecuencia')
        for container in ax.containers:
            ax.bar_label(container)

    for j in range(i + 1, len(axes_flat)):
        fig.delaxes(axes_flat[j])

    plt.tight_layout()
    plt.show()

def analyze_shapiro_qq(df, grid_cols=3, figsize_width=15):
    numeric_cols = [c for c in df.select_dtypes(include='number').columns
                    if df[c].nunique() > 2 and c != 'ID']

    if not numeric_cols:
        print("No hay variables numéricas continuas para analizar.")
        return

    # --- 1. Cálculo Único y Almacenamiento ---
    analysis_results = []

    for col in numeric_cols:
        data_log = np.log1p(df[col].dropna())
        stat, p_value = stats.shapiro(data_log)
        analysis_results.append({
            'Variable': col,
            'W_Statistic': stat,
            'P_Value': p_value,
            'Data_Transformed': data_log
        })
    df_results = pd.DataFrame(analysis_results).drop(columns=['Data_Transformed'])

    print("=== Shapiro-Wilk (Log-Transformed) - Global ===")
    print(df_results.to_string(index=False))

    # --- 3. Generación de Gráficos ---
    total_vars = len(analysis_results)
    rows_needed = math.ceil(total_vars / grid_cols)

    fig, axes = plt.subplots(nrows=rows_needed, ncols=grid_cols,
                             figsize=(figsize_width, 4 * rows_needed))

    axes_flat = axes.flatten() if total_vars > 1 else [axes]

    for i, res in enumerate(analysis_results):
        ax = axes_flat[i]
        col_name = res['Variable']
        p_val = res['P_Value']
        data_plot = res['Data_Transformed']


        stats.probplot(data_plot, dist="norm", plot=ax)
        color_title = 'red' if p_val < 0.05 else 'green'
        p_text = "< 0.001" if p_val < 0.001 else f"{p_val:.3f}"

        ax.set_title(f'{col_name}\nShapiro p-val: {p_text}',
                     fontsize=10, fontweight='bold', color=color_title)
        ax.set_xlabel('')
        ax.set_ylabel('')

    for j in range(i + 1, len(axes_flat)):
        fig.delaxes(axes_flat[j])

    plt.tight_layout()
    plt.show()